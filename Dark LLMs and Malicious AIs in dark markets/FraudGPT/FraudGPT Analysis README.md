# FraudGPT

After writing about [WormGPT](https://github.com/cybershujin/Threat-Actors-use-of-Artifical-Intelligence/blob/main/Dark LLMs and Malicious AIs in dark markets/WormGPT/WormGPT ANALYSIS README.md) it seemed natural that the next dark LLM I would investigate for an analysis would be FraudGPT. Not only were the two models introduced approximately the same time on July 2023, but researcher Daniel Kelley noted that the chatbots shared “foundational similarities,” adding that “while [CanadianKingpin12] didn’t explicitly admit to being responsible for both, it does seem like a plausible scenario because, throughout our communication, it became clear that they could facilitate the sale of both products.” [After WormGPT and FraudGPT, DarkBERT and DarkBART are on the Horizon - Security Boulevard](https://securityboulevard.com/2023/08/after-wormgpt-and-fraudgpt-darkbert-and-darkbart-are-on-the-horizon/)

Notable that this researcher also helped SlashNext in their reporting on WormGPT just prior to this. [WormGPT – The Generative AI Tool Cybercriminals Are Using to Launch Business Email Compromise Attacks](https://slashnext.com/blog/wormgpt-the-generative-ai-tool-cybercriminals-are-using-to-launch-business-email-compromise-attacks/?utm_content=256636270&utm_medium=social&utm_source=twitter&hss_channel=tw-721089455193337856)]

Noted in the conversations Kelley had with the actor, it seems likely there is also a relationship to "DarkBERT":

That said, there was some confusion about what CanadianKingpin12 was saying. According to Kelley, the chatbot developer first said they were developing a bot named DarkBERT, but then later said they already had access to it. Kelley wrote that it seemed likely that CanadianKingpin12 used a [language model](https://arxiv.org/pdf/2305.08596.pdf) called DarkBERT for malicious purposes.

DarkBERT is a language model developed earlier by data intelligence company S2W Security that was trained on data from the dark web with the goal of pushing back against cybercrime rather than enabling it. However, a video shown to Kelley by CanadianKingpin12 talked about DarkBERT as a chatbot used for malicious purposes.

“This discrepancy raises concerns behind the use of ‘DarkBERT’ in this context and suggested that ‘CanadianKingpin12’ may be exploiting S2W’s version of ‘DarkBERT’ while misleadingly presenting it as their own creation,” he wrote.

Although I have no confirmation or intelligence linking the creator of WormGPT and FraudGPT together, I have included a few WormGPT milestones and references in this timeline analysis.

Timeline:

April 13th 2023 a few telegram channels discussing ChatGPT jailbreaks or using it to generate phishing emails have users posting "fraudGPT" with emojiis implying they are making a joke

July 1st, 2023 user "Last" asks questions about LLMs that imply they were training WormGPT at this time. (see screenshot)

Notably prior to this post Last had been selling "Artic Stealer" which is a data stealing trojan and keystroke logger, as well as DCRat (another information stealer). This makes this actor to be the most reputable and clearly demonstrated expertise that seems to add additional credibility to the claimed capabilities of WormGPT.

July 7th WormGPT is advertised - SlashNext [WormGPT - The Generative AI Tool Cybercriminals Are Using to Launch BEC Attacks | SlashNext](https://slashnext.com/blog/wormgpt-the-generative-ai-tool-cybercriminals-are-using-to-launch-business-email-compromise-attacks/)

July 13th, 2023 Fraud GPT Launched

Threat actor CanadianKingpin12 claims to be a verified vendor on various dark marketplaces such as EMPIRE, WHM, TORREZ, WORLD, ALPHABAY and VERSUS but started a telegram channel to advertise this product. The actor's email used on dark web forums appears to be canadiankingpin12@gmail[.]com

July 22nd, 

Telegram channel and posts advertising FraudGPT. 

The subscription fee for FraudGPT starts at **$200 per month** and goes up to **$1,700 per year**. 

Some of the features include: 

- Write malicious code
- Create undetectable malware
- Find non-VBV bins
- Create phishing pages
- Create hacking tools
- Find groups, sites, markets
- Write scam pages/letters
- Find leaks, vulnerabilities
- Learn to code/hack
- Find cardable sites 
- Escrow available 24/7
- 3,000+ confirmed sales/reviews

This activity is reported on July 25th by Netenrich [FraudGPT: The Villain Avatar of ChatGPT | Netenrich](https://netenrich.com/blog/fraudgpt-the-villain-avatar-of-chatgpt)

July 25th, video circulating on darkmarket forums is shared by the CanadianKingpin12 [SlashNext: FraudGPT Captured Demonstration (youtube.com)](https://www.youtube.com/watch?v=uwaH33zGKRY)

July 26th Telegram channel "FraudGPT - Your AI Solution that Creates, Checks and Swipes" created by @fraudgptsales and as of 4/11/2024 has 2,251 subscribers.  Note this channel actually links to an article about the reporting by Netenrich, therefore heavily implying this is the "real" channel for FraudGPT. There is no evidence of CandianKingPin on this channel, however. That said, it does have a page to sign up for services [see screenshot] and the channel seems to periodically announce updates to the product. 

July 28th, 2023 [Is ChatGPT’s ‘evil twin’ FraudGPT itself a scam? (fastcompany.com)](https://www.fastcompany.com/90929870/is-chatgpts-evil-twin-fraudgpt-itself-a-scam)

July 28th on xss[.]is a user posted about the article by Netenrich and the responses were largely skeptical:

**hbv** "It looks like a scam. It can do everything, ChatGPT code sucks, and here a craft from the forum gives out undetectable malware. If he had only written letters, I would have believed it. So letters and ChatGPT can write)"

**madnadbad** "Hamsters are snatching. It's a regular GPT, just no limits"

at least a half dozen channels are created between July 25th and August 8th in Telegram with some variation of "fraudgpt"

July 29th Telegram channel "Star Chat" (t[.]me/planettostar) had a post by 

**world**

**world**
July 29, 2023 02:13 PMQuick note to the majority of the media / whom it may concern, Over the last few weeks the majority of the media have done nothing but give WormGPT AI a bad name and slander it for "ONLY" being in use by Cyber Criminals to exploit / create malware and phishing attacks. We have not seen 1 media outlet talking about how it can be used to help security researchers to look into how AI writes and develops malware / exploits or writes phishing emails in order to create software / programs that can combat and detect the way WormGPT or other AI's that have no restrictions can. We have always believed that seeing what AI can create from a unrestricted point of view will ultimately protect businesses and companies in the long run because having a head start against AI now using tools like WormGPT gives us ways of seeing how it responds to tasks when asked about writing malware, exploits and phishing attacks. We think almost everybody forgets that WormGPT doesn't only have the ability to show viruses/malware/exploits/phishing attacks it can also be used to prevent them too as we've previously shown in an example video further up in this channel specifically the PHP reverse shell and PHP reverse shell protection ones. The majority of the media just think it's some super unworldly tool that's just out to spread chaos and evilness and take over the whole world and destory it and that just isn't the case. Finally in our bio we have always stated that we do not condone criminal activities with the tool. Our target audience has always been targeted to security researchers and security companies in order to give them the ability them to test out our tool and use it to figure ways against protecting against the code that it can write. Imagine having the ability to detect a phishing email that AI has wrote? Without seeing some initally you stand almost 0% chance in detecting one that's been written cleverly by AI. WormGPT AI gives the opportunity for this to happen with all forms of malicious code that AI can produce. We've also previously warned of scammers using our name in a post above in this channel and offered tips on how to protect against being scammed by them. Lastly.... no we are nothing to do with FraudGPT who in our opinion have only added fuel to the fire the media set or have any knowledge or interest in who has developed it. Again we would highly suggest not using it as that GPT really has no leg to stand on in defense. Thank you.

July 29th Telegram channel "FraudGPT4 Official" is created. 

August 1, 2023 updated reporting from Slashnext [AI-Based Cybercrime Tools WormGPT and FraudGPT Could Be The Tip of the Iceberg | SlashNext](https://slashnext.com/blog/ai-based-cybercrime-tools-wormgpt-and-fraudgpt-could-be-the-tip-of-the-iceberg/) "Based on SlashNext’s research, “CanadianKingpin12” initially tried to sell FraudGPT on lower-level cybercrime forums accessible on the clear-net. The clear-net, which refers to the general internet, provides easy access to websites and content through search engines. It’s worth noting, however, that many of the threads created by “CanadianKingpin12” to sell FraudGPT have been removed from these forums...They informed us that “DarkBART” and “DarkBERT”, the new bots they developed, will have internet access and can be seamlessly integrated with [Google Lens](https://lens.google/). This integration enables the ability to send text accompanied by images...We’d like to clarify something here, however: During our exchange with “CanadianKingpin12,” we encountered conflicting information. Initially, they mentioned their involvement in the development of a bot named “DarkBERT,” but later claimed to simply have *access* to it. While there is some speculation in this comment, our belief is that “CanadianKingpin12” has managed to leverage a language model called “DarkBERT” for malicious use." (*note that this story gets picked up and reported in other outlets without this caveat, only stating that the same actor created darkbert and darkbart* ) the article goes on to explain the discrepancies in the chat with the actor and goes on to say, "This discrepancy raises concerns behind the use of “DarkBERT” in this context and suggests that “CanadianKingpin12” may be exploiting S2W’s version of “DarkBERT” while misleadingly presenting it as their own creation."

August 1st, 2023 [There’s no reason to panic over WormGPT | TechCrunch](https://techcrunch.com/2023/08/01/theres-no-reason-to-panic-over-wormgpt/?guccounter=1&guce_referrer=aHR0cHM6Ly9tYWx3YXJlLm5ld3Mv&guce_referrer_sig=AQAAAFizToIaEvu3abscT3Wc7P3dKnZSxkUtAVG2sBG-ZuRfxXTTPCHQ1XWJYz6fuK7-LDppET-GOH8RmC3g2o64BeaXWu1vWpq8MpXXUytXT-sbfL_jy6c09Qj7OiVTFEqsTKc7DIDrp3Qr3iK2CuPScnbO9OzC8_z1jbewedUF8P4h) "The takeaway is, LLMs like WormGPT and FraudGPT might generate sensationalist headlines — and, yes, malware. But they definitely won’t cause the downfall of corporations or governments. Could they in theory enable scammers with limited English skills to generate targeted business emails, as SlashNext’s analysis suggests? Perhaps. But more realistically, they’ll at most make a quick buck for the folks (scammers?) who built them." *this article is linked to or quoted at least six times in the next week in darkmarket and telegram channels*

August 5th 2023 user Rat-Botnet on xss[.]is remarks that FraudGPT is "not as good as the propagandists say, I bought their service, I don't recommend you buy it if you need proof, I can provide it"

August 8th, 2023 Krebs did an excellent article on this: [Meet the Brains Behind the Malware-Friendly AI Chat Service ‘WormGPT’ – Krebs on Security](https://krebsonsecurity.com/2023/08/meet-the-brains-behind-the-malware-friendly-ai-chat-service-wormgpt/) which basically revealed that this user appears to be Rafael Morais from Porto, a coastal city in Portugal.

August 8th, 2023 last posts an "end to the WormGPT project" and uses the phrase "we" implying there were collaborating with multiple people [see WormGPT Analysis README](https://github.com/cybershujin/Threat-Actors-use-of-Artifical-Intelligence/blob/main/Dark LLMs and Malicious AIs in dark markets/WormGPT/WormGPT ANALYSIS README.md)

August 31, 2023 dozens of telegram posts across various channels advertising "FraudGPT - Blackhat ChatGPT" for sale starting at $500 a month

October 13, 2023 xss[.]is forum post on topic "FraudGPT" has a user post

**ktpm23**

"Alas, all the developments in this area are just assemblies of chat gpt or other language models, and as far as I understand, they are not trained on a dataset on dark topics, only they have removed censorship. The reasons, as I understood, are trivial: after talking a little with people who train neural networks and who try to make such dark models, it is extremely expensive to make your own, you need money, knowledge of how to do and how to bypass all this (it is difficult to prompt here and everything is learned by the poke method), and it is also difficult to collect a dataset on the topic, not everything is in the public domain, and you also need a powerful hardware server for rent. And the machine often just gives out banalities or generally unpredictable things that even you don't understand how it is."

March 1st users on xss[.]is ask if "Just a question? has the FraudGPT operation shut down?" and two other users answer that they believe they did

