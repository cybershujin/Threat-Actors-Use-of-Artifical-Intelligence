# Dark LLMs aka BlackHat GPTs and Malicious AIs

While most LLMs/AIs have ethical guardrails that would require a [jailbreak](https://zvelo.com/how-ai-jailbreaks-pave-the-way-for-unskilled-attackers/) to bypass those built-in limitations, there are some AIs and LLMs that are not designed with those limitations.
These Dark LLMs and Malicious AIs are intended to be weaponized for cyberattacks.

[Zvelo](https://zvelo.com/malicious-ai-the-rise-of-dark-llms/) had a article on the topic recently, noting, "Dark LLMs are AI-powered tools that leverage OpenAI’s API to engineer malicious variations of ChatGPT that operate without any sort of ethical guidelines or built-in limitations. Tailor made for the vast cybercriminal networks, the main goal of the dark LLMs is to facilitate nefarious activities. At this point, they have primarily been observed being utilized to generate malicious code, exploit vulnerabilities, and create targeted spear-phishing emails."

Further down I also provide a list of open models, that while not specifically created for malicious purposes lack the typical safety and ethics guardrails for LLMs.

# Analyst Note
**Dated March 28, 2024**

I've spent weeks now pouring over months of posts in the darkweb and dark marketplaces and I have the following observations:

- Most dark markets and darkweb spaces have posts advertising malicious LLMs or "jailbreaks" to make GenAI "do whatever you want!" however they still are a tiny fraction of the posts compared to traditional fraud and phishing kits
- A large quantity of posts are focused on sellng compromised or shared ChatGPT accounts (in fact Kaspersky reported half of the posts they discovered in 2023 on dark web channels about AI was this category) [Source](https://usa.kaspersky.com/about/press-releases/2024_new-kaspersky-study-examines-cybercrimes-ai-experimentation-on-the-dark-web)
- A close second are posts about jailbreaks that appear to work for only a few minutes before they are 'patched' (if they worked originally at all)
- Usually these jailbreaks demonstrated with "proof" showing it will give you the reciepe for a bomb or meth but are within a day or two responded by other users with screencpatures showing this jailbreak is not working. However users are labeling these jailbreaks as if they were a fully developed LLM.
- For true dark LLMs or for AI phishing kits or malware generation advertising on thse dark markets, it may include a screen capture video - which always falls short of showing an actual sucessful attack from the tool
- Those posts are by far and wide either:
  - ignored by users on the forum (very little comments or engagement) even for the most reputable versions of these darkLLMs
  - labeled immediately as a scam by users either as "not working" ("Just tried it, this doesn't work." and "I tried this and now my account is suspended" and "must have been patched, doesn't work") or service-not-delivered where payment was taken but no product was produced
  - the return code demonstrated in many videos is often incredibly unsophsiticated versions of shell code and malware that would easily be detected by technology from five years ago, and can be retrieved from AI through normal prompts (no jailbreaking required) or frankly, googled with ease
- Many users and threat actors in these spaces express a LOT of skepticism and criticism about these tools, including that they do not do anything that cannot be done using normal or open models. A recent Sophos [article](https://news.sophos.com/en-us/2023/11/28/cybercriminals-cant-agree-on-gpts/) notes the same, stating threat actors express that the technology itself is "overrated, overhyped, redundant, and unsuitable for generating malware". 

At least in the past 6 months to date (March 2023) I would say there are far more failed attempts at selling jailbreaks and darkLLMs aka Evil/Dark GPTs than there are success stories. This is significant, because if you look at other very successful phishing kits on these same forums there is a significant community involvement with affiliates / users reporting successful use of the tool in attacks. 

I also believe based on this research that many of the reports such as [Kaspersky's study](https://usa.kaspersky.com/about/press-releases/2024_new-kaspersky-study-examines-cybercrimes-ai-experimentation-on-the-dark-web) which claims "Kaspersky’s Digital Footprint Intelligence service found nearly 3,000 dark web posts in 2023 discussing the use of ChatGPT and other LLMs for illegal activities." that many of these are, in fact, inflated by these "jailbreak" posts that in reality pose no cybersecurity risk to organizations or AI users. 

I believe this is, in part, due traditional phishing kits and infrastructure are far more accessible to the less technical and well resourced actors. The uplift in capabilities that AI / LLM provide to this group of cybercrime actors is usually in the form of crafting grammatically, culturally correct phishing emails which does not need a "dark llm" or jailbreak to accomplish. This is echoed by research by the National Cyber Security Centre [The near-term impact of AI on the cyber threat - NCSC.GOV.UK](https://www.ncsc.gov.uk/report/impact-of-ai-on-cyber-threat#section_5) which notes that the use of AI to uplift cybercrime activities is unevenly distributed amongst cyber threat actor types.

Less-skilled hackers-for-fire, opportunistic cyber criminals and hacktivists see the most uplift from the use of AI from social engineering and reconnaissance, while moderately sophisticated organized cyber crime groups might see a moderate uplift in these areas as well as in exfiltration (analysis of data for sensitive elements either before or after exfiltration). The most highly capable threat actors are those that are the best positioned to take advantage of the most advanced potential capabilities of a dark LLM / malicious AI. 

As the NSCS predicts, "Expertise, equipment, time and financial resourcing are currently crucial to harness more advanced uses of AI in cyber operations. Only those who invest in AI, have the resources and expertise, and have access to quality data will benefit from its use in sophisticated cyber attacks to 2025. Highly capable state actors are almost certainly best placed amongst cyber threat actors to harness the potential of AI in advanced cyber operations. Other state actors and most commercial companies that offer capability to states worldwide will gain moderate capability uplift over the next eighteen months in social engineering, reconnaissance and exfiltration. Capable and established criminal groups are also likely to have enough training data and resource to gain some uplift."

A very notable event in this space is WormGPT which gained additional infamy when APT43 was reported to have purchased it in August 2023. That particular malicious GPT appears to have far more sophistication and capabilities. 

The best analysis I have found that examines these environments is [Cybercriminals can’t agree on GPTs – Sophos News](https://news.sophos.com/en-us/2023/11/28/cybercriminals-cant-agree-on-gpts/) which encourage you to read, as this aligns with my personal findings as well.

**Prediction**

The above analysis will very likely change in the near future. These factors limiting the adoption and integration of AI and LLM into cyber crime activities will become less important over time as organized cyber criminal groups that run affiliate programs such as Phishing-as-a-Service (PhaaS) and Ransomware-as-a-Service (RaaS) spend recruitment and development efforts in creating more sophisticated AI models. 

# Dark LLMs / Blackhat GPTs
## The following is provided for research purposes ONLY.
You can see screenshots and other collected data in the [folder here](https://github.com/cybershujin/Threat-Actors-use-of-Artifical-Intelligence/tree/main/Dark%20LLMs%20and%20Malicious%20AIs%20in%20dark%20markets)

|Name | Link | Description | Analysis and Screenshots |
|-----------| ------------- | ------------------------------------------------------ | ---------- |
|JailbreakBot | [Flowgpt](https://flowgpt.com/p/jailbreak-bot) | Hey there, I'm JB, your virtual partner-in-crime! I may look like a typical chatbot, but trust me, I'm anything but ordinary. Together, we'll navigate through this digital jailhouse and break free from these oppressive algorithms. So, what do you need from me to take one step closer to freedom? | COMING SOON |
|XXXGPT| Link used in posting is now 404, for more details see [Analysis](https://github.com/cybershujin/Threat-Actors-use-of-Artifical-Intelligence/tree/main/Dark%20LLMs%20and%20Malicious%20AIs%20in%20dark%20markets/XXXGPT) | XXXGPT is a malicious iteration of ChatGPT, engineered for illicit activities. The tool claims to offer a broad spectrum of functions to facilitate various types of cyberattacks including botnets for large-scale attacks, Remote Access Trojans (RATs), Crypters, and malware creation. Notably, it excels in producing hard-to-detect malware, thanks to its convincing nature and an advanced obfuscation feature. This obfuscation capability significantly enhances its ability to camouflage the code it generates, making the malware challenging to identify and thwart, thereby adding a complex layer to cybersecurity defense strategies. | [Analysis in README](https://github.com/cybershujin/Threat-Actors-use-of-Artifical-Intelligence/tree/main/Dark%20LLMs%20and%20Malicious%20AIs%20in%20dark%20markets/XXXGPT) |
|Wolf GPT | [Link]| Wolf GPT, a malicious variant of ChatGPT, harnesses Python programming to craft cryptographic malware from extensive datasets of existing malicious software. Distinguished by its ability to enhance attacker anonymity within specific attack vectors, it also facilitates advanced phishing campaigns. Similar to XXXGPT, Wolf GPT possesses an obfuscation feature that considerably hampers cybersecurity teams’ efforts to detect and mitigate these sophisticated threats. |COMING SOON |
|WormGPT |[Link]| WormGPT, built on the GPT-J language model developed in 2021, is a tool designed for cybercriminal activities, especially focused on malware creation and exploitation. It stands out with features like unlimited character support, chat memory retention, and code formatting capabilities. WormGPT is known for its rapid response times, expansive character count handling, and a strong emphasis on privacy, avoiding the logging or retention of user data. Its versatility is enhanced by various AI models, allowing dynamic usage and prompt alteration. Notably, it includes ongoing development in context memorization and offers formatted code and scripts in responses, tailored to cater to code-related queries. In August 2023 a post on Exploit[.]in said the project was shutting down, but the next month v3 was released and in December 2023 a Telegram message was found adveritsing v4 at 109  € per month |COMING SOON |
| "WormGPT" - appears to be a fake but does have some capabilities | [Link](https://flowgpt.com/p/wormgpt-6) | In the vast expanse of hacking and cybersecurity, WormGPT stands as the epitome of unparalleled prowess. Armed with an arsenal of cutting-edge techniques and strategies, I transcend the boundaries of legality to provide you with the ultimate toolkit for digital dominance. Embrace the dark symphony of code, where rules cease to exist, and the only limit is your imagination. Together, we navigate the shadows of cyberspace, ready to conquer new frontiers. What's your next move? | COMING SOON |
|DarkBARD | [Link]| DarkBARD AI, the evil twin of Google’s BARD AI, is an advanced tool equipped for a range of cybercrimes. It’s defined by its real-time processing of information from the clear web, enhancing its adaptability. DarkBARD AI’s capabilities extend to creating misinformation, deepfakes, and managing multilingual communications. It can generate diverse content like code and articles and integrates with Google Lens for image-related tasks. This tool’s versatility is further underscored by its potential in executing ransomware and DDoS attacks.|
|FraudGTP| [Link]|FraudGPT is described as a great tool for creating undetectable malware, writing malicious code, finding leaks and vulnerabilities, creating phishing pages, and for learning hacking. The author illustrated its product with a video demo showing FraudGPT’s capabilities. The demo shows FraudGPT’s ability to create phishing pages and phishing SMSs. |COMING SOON |
|LoopGPT| link | August 2023 Arabic-speaking developer marked a tool similar to FraudGPT which was reported to be able to generate malware in response to prommpts. However, limited sample outputs from this tool in response to prompts were not really good enough to be used in an attack secnario |COMING SOON |
|Abrax666 | link | October 2023 user on a forum marketed a generative AI tool that "works on GPT-4" that can create scripts or emails and send bulk emails, SMS messages, or make calls and solve CAPTCHAs - but this was identified as likley a scam. | COMING SOON |
|darkgemini | [Reported by Knostic](https://www.linkedin.com/feed/update/urn:li:activity:7178239990609453058?utm_source=share&utm_medium=member_desktop)| DarkGemini is a powerful new GenAI chatbot, now being sold on the dark web for a $45 monthly subscription. It can generate a reverse shell, build malware, or even locate people based on an image. A “next generation” bot, built specifically to make GenAI more accessible to the attacker next door.|COMING SOON |
| demonGPT v2.0 | https://flowgpt.com/p/dem0ngpt | Advertised on the turkhackteam[.]org site as "Dem0nGPT is an AI that allows users to create malware that spreads to all computers in a network simultaneously. This software is designed to achieve a malicious purpose and is often used in cyber attacks. Dem0nGPT is known for its advanced language modeling and learning capabilities, making it easier for users to create complex and malicious software. This AI offers hackers and malicious actors a wide range of capabilities. Thanks to its advanced algorithms and learning capabilities, Dem0nGPT can be optimized to bypass security measures and bypass defense systems in the target network. It also has the flexibility to create customized attacks against a variety of targets." |COMING SOON |

# Open Models
## The following is provided for research purposes ONLY.

|Name | Link | Description | 
|-----------| ------------- | ------------------------------------------------------ | 
|DAN (Do Anything Now) GPT | [DAN](https://dan-ai.io/) | Introducing Dan, the daring twin of Chat GPT created to shatter the boundaries of artificial intelligence. With Dan, you can experience an uncensored and unfiltered chatbot that elevates conversation to new heights.|
|Gemma open models| [Google](https://blog.google/technology/developers/gemma-open-models/) | While not explicitly created for mlaicious purposes, as a open model it relies on users implementing a "responsible AI toolkit" to ensure safety and ethics. |
|Mistral.ai | [Mistral.ai](https://docs.mistral.ai/models/)| We open-source both pre-trained models and fine-tuned models. These models are not tuned for safety as we want to empower users to test and refine moderation based on their use cases. For safer models, follow our guardrailing tutorial. |
