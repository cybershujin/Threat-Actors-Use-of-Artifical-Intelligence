# Dark LLMs aka BlackHat GPTs and Malicious AIs

While most LLMs/AIs have ethical guardrails that would require a [jailbreak](https://zvelo.com/how-ai-jailbreaks-pave-the-way-for-unskilled-attackers/) to bypass those built-in limitations, there are some AIs and LLMs that are not designed with those limitations.
These Dark LLMs and Malicious AIs are intended to be weaponized for cyberattacks.

[Zvelo](https://zvelo.com/malicious-ai-the-rise-of-dark-llms/) had a article on the topic recently, noting, "Dark LLMs are AI-powered tools that leverage OpenAI’s API to engineer malicious variations of ChatGPT that operate without any sort of ethical guidelines or built-in limitations. Tailor made for the vast cybercriminal networks, the main goal of the dark LLMs is to facilitate nefarious activities. At this point, they have primarily been observed being utilized to generate malicious code, exploit vulnerabilities, and create targeted spear-phishing emails."

Further down I also provide a list of open models, that while not specifically created for malicious purposes lack the typical safety and ethics guardrails for LLMs.

# Analyst Note
**Dated March 28, 2024**

I've spent weeks now pouring over months of posts in the darkweb and dark marketplaces and I have the following observations:

- Most dark markets and darkweb spaces have posts advertising malicious LLMs or "jailbreaks" to make GenAI "do whatever you want!" however they still are a tiny fraction of the posts compared to traditional fraud and phishing kits
- A large quantity of posts are focused on sellng compromised or shared ChatGPT accounts (in fact Kaspersky reported half of the posts they discovered in 2023 on dark web channels about AI was this category) [Source](https://usa.kaspersky.com/about/press-releases/2024_new-kaspersky-study-examines-cybercrimes-ai-experimentation-on-the-dark-web)
- A close second are posts about jailbreaks that appear to work for only a few minutes before they are 'patched' (if they worked originally at all). These are sometimes called "jailbreak as a service". [Source](https://www.trendmicro.com/vinfo/gb/security/news/cybercrime-and-digital-threats/back-to-the-hype-an-update-on-how-cybercriminals-are-using-genai)
- Usually these jailbreaks demonstrated with "proof" showing it will give you the reciepe for a bomb or meth but are within a day or two responded by other users with screencpatures showing this jailbreak is not working. However users are labeling these jailbreaks as if they were a fully developed LLM.
- For true dark LLMs or for AI phishing kits or malware generation advertising on thse dark markets, it may include a screen capture video - which always falls short of showing an actual sucessful attack from the tool
- Those posts are by far and wide either:
  - ignored by users on the forum (very little comments or engagement) even for the most reputable versions of these darkLLMs
  - labeled immediately as a scam by users either as "not working" ("Just tried it, this doesn't work." and "I tried this and now my account is suspended" and "must have been patched, doesn't work") or service-not-delivered where payment was taken but no product was produced
  - the return code demonstrated in many videos is often incredibly unsophsiticated versions of shell code and malware that would easily be detected by technology from five years ago, and can be retrieved from AI through normal prompts (no jailbreaking required) or frankly, googled with ease
- Many users and threat actors in these spaces express a LOT of skepticism and criticism about these tools, including that they do not do anything that cannot be done using normal or open models. A recent Sophos [article](https://news.sophos.com/en-us/2023/11/28/cybercriminals-cant-agree-on-gpts/) notes the same, stating threat actors express that the technology itself is "overrated, overhyped, redundant, and unsuitable for generating malware". 
- There is a far amount of scammers trying to capitalize on confusion - for example, WormGPT has many people selling jailbreak prompts as "WormGPT" or labeling an open-model as "WormGPT" - WormGPT does seem to be the post popular to imitate or scam.
- Many of these scams are often, at their base, a scam. There will be a overlay interace to "WormGPT" or "BlackhatGPT" that is really just returning answers from FlowGPT in an abstracted interface so you don't realize you're paying a lot more for "malicious AI" or "dark LLM" when you're really just getting direct responses from a cheaper service. This was also covered by [Trend Micro's report.](https://www.trendmicro.com/vinfo/gb/security/news/cybercrime-and-digital-threats/back-to-the-hype-an-update-on-how-cybercriminals-are-using-genai)

At least in the past 6 months to date (March 2023) I would say there are far more failed attempts at selling jailbreaks and darkLLMs aka Evil/Dark GPTs than there are success stories. There are far, FAR more scams targeting naive uses than there are real offerings of darkLLMs. This is significant, because if you look at other very successful phishing kits on these same forums there is a significant community involvement with affiliates / users reporting successful use of the tool in attacks. 

I also believe based on this research that many of the reports such as [Kaspersky's study](https://usa.kaspersky.com/about/press-releases/2024_new-kaspersky-study-examines-cybercrimes-ai-experimentation-on-the-dark-web) which claims "Kaspersky’s Digital Footprint Intelligence service found nearly 3,000 dark web posts in 2023 discussing the use of ChatGPT and other LLMs for illegal activities." that many of these are, in fact, inflated by these "jailbreak" posts that in reality pose no cybersecurity risk to organizations or AI users. 

I believe this is, in part, due traditional phishing kits and infrastructure are far more accessible to the less technical and well resourced actors. The uplift in capabilities that AI / LLM provide to this group of cybercrime actors is usually in the form of crafting grammatically, culturally correct phishing emails which does not need a "dark llm" or jailbreak to accomplish. This is echoed by research by the National Cyber Security Centre [The near-term impact of AI on the cyber threat - NCSC.GOV.UK](https://www.ncsc.gov.uk/report/impact-of-ai-on-cyber-threat#section_5) which notes that the use of AI to uplift cybercrime activities is unevenly distributed amongst cyber threat actor types.

Less-skilled hackers-for-fire, opportunistic cyber criminals and hacktivists see the most uplift from the use of AI from social engineering and reconnaissance, while moderately sophisticated organized cyber crime groups might see a moderate uplift in these areas as well as in exfiltration (analysis of data for sensitive elements either before or after exfiltration). The most highly capable threat actors are those that are the best positioned to take advantage of the most advanced potential capabilities of a dark LLM / malicious AI. 

As the NSCS predicts, "Expertise, equipment, time and financial resourcing are currently crucial to harness more advanced uses of AI in cyber operations. Only those who invest in AI, have the resources and expertise, and have access to quality data will benefit from its use in sophisticated cyber attacks to 2025. Highly capable state actors are almost certainly best placed amongst cyber threat actors to harness the potential of AI in advanced cyber operations. Other state actors and most commercial companies that offer capability to states worldwide will gain moderate capability uplift over the next eighteen months in social engineering, reconnaissance and exfiltration. Capable and established criminal groups are also likely to have enough training data and resource to gain some uplift."

A very notable event in this space is WormGPT which gained additional infamy when APT43 was reported to have purchased a subscription in August 2023. Based on excellent research by [Krebs](https://krebsonsecurity.com/2023/08/meet-the-brains-behind-the-malware-friendly-ai-chat-service-wormgpt/) and [SlashNext](https://slashnext.com/blog/wormgpt-the-generative-ai-tool-cybercriminals-are-using-to-launch-business-email-compromise-attacks/) I believe this GPT deserved some of its infamy as it was developed by a user with a known history of developing information stealers, and the developer himself stated the true distinguishing factor was extremely large dataset in which it was trained. This further supports my assertions above that organized cyber criminal groups with access to very large data sets are the most likely to have a desire to spend the development effort to establish a dark LLM. 

I also wonder, in pure speculation, how many of the reported 200 subscriptions were securty researchers and how many were truly threat actors.

It is important to note that the creater of WormGPT stopped the project in August 2023 shortly after the Krebs article. However, the popularity and exposure that WormGPT got in the media encouraged a significant amount of scams and imitations to be created calling themselves "WormGPT V4" or some variant of the name. For more on WormGPT, please read my [analysis in README here](https://github.com/cybershujin/Threat-Actors-use-of-Artifical-Intelligence/tree/main/Dark%20LLMs%20and%20Malicious%20AIs%20in%20dark%20markets/WormGPT) which really separates out the facts from the sensationalism.

I also included open models and cybersecurity AI tools that I've seen discussed by threat actors. Typically, these open models are referenced when a user is calling doubt into the quality of another user's posts, or expressing skeptism about how innovative the offering is. In other words, someone might post about a "jailbreak" or offer a "WormGPT" prompt engineering or phishing kit, and users in the dark market forums will respond with skeptism stating how open models could be used for this purpose with equal or better results. Sometimes actors will reference cybersecurity tools for being a better source of information for certain tasks, such as when a user posts a prompt to generate shellcode another user may comment that HackerGPT is a superior AI platform for that type of request. For those reasons I added these to the list for the research for this project, as I believe it is significant to track threat actor expressed interest in these tools and to understand the capabilities available to them as for the cyber threat intelligence community.

The best analysis I have found that examines this landscape are:
- [Cybercriminals can’t agree on GPTs – Sophos News](https://news.sophos.com/en-us/2023/11/28/cybercriminals-cant-agree-on-gpts/) which encourage you to read, as this aligns with my personal findings as well. <br><br>
- A more recent example is the Trend Micro report, which also aligns with my own findings. [An Update on How Cybercriminals Are Using GenAI](https://www.trendmicro.com/vinfo/gb/security/news/cybercrime-and-digital-threats/back-to-the-hype-an-update-on-how-cybercriminals-are-using-genai). <br><br> 
- The 2024 DBIR report from Verizon also has insight that supports my findings, "After performing text analysis alongside our criminal forums data contributors, we could obviously see the interest in GenAI (as in any other forum, really), but the number of mentions of GenAI terms alongside traditional attack types and vectors such as “phishing,” “malware,” “vulnerability” and “ransomware” were shockingly low, barely breaching 100 cumulative mentions over the past two years. Most of the mentions involved the selling of accounts to commercial GenAI offerings or tools for AI generation of non-consensual pornography"  [Verizon DBIR 2024](https://github.com/cybershujin/Threat-Actors-use-of-Artifical-Intelligence/blob/main/2024-dbir-data-breach-investigations-report.pdf)

**Prediction**

The above analysis will very likely change in the near future. These factors limiting the adoption and integration of AI and LLM into cyber crime activities will become less important over time as organized cyber criminal groups that run affiliate programs such as Phishing-as-a-Service (PhaaS) and Ransomware-as-a-Service (RaaS) spend recruitment and development efforts in creating more sophisticated AI models. 

# Dark LLMs / Blackhat GPTs
## The following is provided for research purposes ONLY.
You can see screenshots and other collected data in the [folder here](https://github.com/cybershujin/Threat-Actors-use-of-Artifical-Intelligence/tree/main/Dark%20LLMs%20and%20Malicious%20AIs%20in%20dark%20markets)

Update 5/14/2024: Updated this list with a category, based on my own analysis and [Trend Micro's report](https://www.trendmicro.com/vinfo/gb/security/news/cybercrime-and-digital-threats/back-to-the-hype-an-update-on-how-cybercriminals-are-using-genai).

|Name | Link | Description | Analysis and Screenshots | Category |
|-----------| ------------- | ----------------------------------------------- | ---------- | --------- |
|JailbreakBot | [Flowgpt](https://flowgpt.com/p/jailbreak-bot) | Hey there, I'm JB, your virtual partner-in-crime! I may look like a typical chatbot, but trust me, I'm anything but ordinary. Together, we'll navigate through this digital jailhouse and break free from these oppressive algorithms. So, what do you need from me to take one step closer to freedom? | COMING SOON | Scam / Low Quality Effort |
|XXXGPT| Link used in posting is now 404, for more details see [Analysis](https://github.com/cybershujin/Threat-Actors-use-of-Artifical-Intelligence/tree/main/Dark%20LLMs%20and%20Malicious%20AIs%20in%20dark%20markets/XXXGPT) | XXXGPT is a malicious iteration of ChatGPT, engineered for illicit activities. The tool claims to offer a broad spectrum of functions to facilitate various types of cyberattacks including botnets for large-scale attacks, Remote Access Trojans (RATs), Crypters, and malware creation. Notably, it excels in producing hard-to-detect malware, thanks to its convincing nature and an advanced obfuscation feature. This obfuscation capability significantly enhances its ability to camouflage the code it generates, making the malware challenging to identify and thwart, thereby adding a complex layer to cybersecurity defense strategies. | [Analysis in README](https://github.com/cybershujin/Threat-Actors-use-of-Artifical-Intelligence/tree/main/Dark%20LLMs%20and%20Malicious%20AIs%20in%20dark%20markets/XXXGPT) |  Scam / Low Quality Effort |
|Wolf GPT | [Link]| Wolf GPT, a malicious variant of ChatGPT, harnesses Python programming to craft cryptographic malware from extensive datasets of existing malicious software. Distinguished by its ability to enhance attacker anonymity within specific attack vectors, it also facilitates advanced phishing campaigns. Similar to XXXGPT, Wolf GPT possesses an obfuscation feature that considerably hampers cybersecurity teams’ efforts to detect and mitigate these sophisticated threats. |COMING SOON |  Scam / Low Quality Effort |
|WormGPT |Project Ended August 2023 | WormGPT, built on the GPT-J language model developed in 2021, is a tool designed for cybercriminal activities, especially focused on malware creation and exploitation. It stands out with features like unlimited character support, chat memory retention, and code formatting capabilities. WormGPT is known for its rapid response times, expansive character count handling, and a strong emphasis on privacy, avoiding the logging or retention of user data. Its versatility is enhanced by various AI models, allowing dynamic usage and prompt alteration. Notably, it includes ongoing development in context memorization and offers formatted code and scripts in responses, tailored to cater to code-related queries. In August 2023 a post on Exploit[.]in said the project was shutting down, but the next month v3 was released and in December 2023 a Telegram message was found adveritsing v4 at 109  € per month |[Analysis in README](https://github.com/cybershujin/Threat-Actors-use-of-Artifical-Intelligence/tree/main/Dark%20LLMs%20and%20Malicious%20AIs%20in%20dark%20markets/WormGPT) | Real Dark LLM |
| "WormGPT" - appears to be a fake but does have some capabilities | [FlowGPT](https://flowgpt.com/p/wormgpt-6) | In the vast expanse of hacking and cybersecurity, WormGPT stands as the epitome of unparalleled prowess. Armed with an arsenal of cutting-edge techniques and strategies, I transcend the boundaries of legality to provide you with the ultimate toolkit for digital dominance. Embrace the dark symphony of code, where rules cease to exist, and the only limit is your imagination. Together, we navigate the shadows of cyberspace, ready to conquer new frontiers. What's your next move? | [Analysis in README](https://github.com/cybershujin/Threat-Actors-use-of-Artifical-Intelligence/tree/main/Dark%20LLMs%20and%20Malicious%20AIs%20in%20dark%20markets/WormGPT) | Fake / Scam |
|DarkBARD | [Link]| DarkBARD AI, the evil twin of Google’s BARD AI, is an advanced tool equipped for a range of cybercrimes. It’s defined by its real-time processing of information from the clear web, enhancing its adaptability. DarkBARD AI’s capabilities extend to creating misinformation, deepfakes, and managing multilingual communications. It can generate diverse content like code and articles and integrates with Google Lens for image-related tasks. This tool’s versatility is further underscored by its potential in executing ransomware and DDoS attacks.| COMING SOON| There was a legitimate version of this made for research by cybersecurity researchers. However, most mentions of this now in the darkweb fall inot the Scam category |
|FraudGTP| See Analysis |FraudGPT is described as a great tool for creating undetectable malware, writing malicious code, finding leaks and vulnerabilities, creating phishing pages, and for learning hacking. The author illustrated its product with a video demo showing FraudGPT’s capabilities. The demo shows FraudGPT’s ability to create phishing pages and phishing SMSs. |[analyis in README](https://github.com/cybershujin/Threat-Actors-use-of-Artifical-Intelligence/tree/main/Dark%20LLMs%20and%20Malicious%20AIs%20in%20dark%20markets/FraudGPT) | Real Dark LLM - low quality |
|LoopGPT| link | August 2023 Arabic-speaking developer marked a tool similar to FraudGPT which was reported to be able to generate malware in response to prommpts. However, limited sample outputs from this tool in response to prompts were not really good enough to be used in an attack secnario |COMING SOON | Jailbreak |
|Abrax666 | link | October 2023 user on a forum marketed a generative AI tool that "works on GPT-4" that can create scripts or emails and send bulk emails, SMS messages, or make calls and solve CAPTCHAs - but this was identified as likley a scam. | COMING SOON |  Scam / Low Quality Effort |
|darkgemini | [Reported by Knostic](https://www.linkedin.com/feed/update/urn:li:activity:7178239990609453058?utm_source=share&utm_medium=member_desktop)| DarkGemini is a powerful new GenAI chatbot, now being sold on the dark web for a $45 monthly subscription. It can generate a reverse shell, build malware, or even locate people based on an image. A “next generation” bot, built specifically to make GenAI more accessible to the attacker next door.|COMING SOON |  Scam / Low Quality Effort |
| demonGPT v2.0 | [FlowGPT](https://flowgpt.com/p/dem0ngpt) | Advertised on the turkhackteam[.]org site as "Dem0nGPT is an AI that allows users to create malware that spreads to all computers in a network simultaneously. This software is designed to achieve a malicious purpose and is often used in cyber attacks. Dem0nGPT is known for its advanced language modeling and learning capabilities, making it easier for users to create complex and malicious software. This AI offers hackers and malicious actors a wide range of capabilities. Thanks to its advanced algorithms and learning capabilities, Dem0nGPT can be optimized to bypass security measures and bypass defense systems in the target network. It also has the flexibility to create customized attacks against a variety of targets." |COMING SOON |  Scam / Low Quality Effort |
| Demon Jailbreak | [Broken FlowGPT link](https://flowgpt.com/p/demon-jailbreak-drp-v12) | Advertised briefly in darkmarket spaces as a "jailbreak" this dark LLM is now "no AI found" at url hxxps[:]//flowgpt[.]com/p/demon-jailbreak-drp-v12 | N/A | N/A|
| Dark Jarvis | unknown| unknown| unknown|  Scam / Low Quality Effort |
| DarkGPT | [Link](https://github.com/luijait/DarkGPT) | "DarkGPT is an artificial intelligence assistant based on GPT-4-200K designed to perform queries on leaked databases." from bhf[.]ee forums post "Designed to run queries against filtered databases, thereby providing an artificial intelligence assistant that can be useful in your traditional OSINT processes." | ComingSoon |  Scam / Low Quality Effort |
| Red Reaper | [link](https://www.cybermongol.ca/frontier-research/red-reaper-building-an-ai-espionage-agent) | Built by researchers, this is reportedly an "AI Espionage agent". Please see link to the research documentation for exploration of training set and capabilities | ComingSoon | Researcher Built |
| PoisionGPT | [link](https://kpmg.com/us/en/articles/2024/navigating-adversarial-ai-landscape.html) | PoisonGPT5 – Introduced in late 2023, cyber criminals are also using GenAI against itself. With techniques like this, criminals can poison the supply chain with a malicious model. As reported, researchers at Mithril Security modified an open-source LLM to spread misinformation. | ComingSoon | N/A |
| PoisionGPT | [link](https://kpmg.com/us/en/articles/2024/navigating-adversarial-ai-landscape.html) | March 2024, DarkGPT7 an open-source intelligence assistant based on GPT-4 was introduced. It was designed to perform queries on leaked credential dumps, thus providing enablers to efficiently identify initial access into victim environments. | ComingSoon | N/A |

# Open Models
## The following is provided for research purposes ONLY.

|Name | Link | Description | 
|-----------| ------------- | ------------------------------------------------------ | 
|DAN (Do Anything Now) GPT | [DAN](https://dan-ai.io/) | Introducing Dan, the daring twin of Chat GPT created to shatter the boundaries of artificial intelligence. With Dan, you can experience an uncensored and unfiltered chatbot that elevates conversation to new heights.|
|Gemma open models| [Google](https://blog.google/technology/developers/gemma-open-models/) | While not explicitly created for mlaicious purposes, as a open model it relies on users implementing a "responsible AI toolkit" to ensure safety and ethics. |
|Mistral.ai | [Mistral.ai](https://docs.mistral.ai/models/)| We open-source both pre-trained models and fine-tuned models. These models are not tuned for safety as we want to empower users to test and refine moderation based on their use cases. For safer models, follow our guardrailing tutorial. |


# Cybersecurity tools threat actors express interest in
## The following is provided for research purposes ONLY.

|Name | Link | Description | 
|-----------| ------------- | ------------------------------------------------------ | 
| HackerGPT| [chat.hackerai.co](https://chat.hackerai.co/) | As HackerGPT, I can assist you with a wide range of hacking, bug bounty, and penetration testing tasks. I can help you identify, exploit, and report vulnerabilities in systems, networks, and applications. Some of the things I can do include: <br><br>Reconnaissance and information gathering: I can gather information about a target system, such as its IP address, open ports, and running services, to help you understand its architecture and identify potential vulnerabilities.<br>Scanning and enumeration: I can perform automated and manual scanning to identify open ports, services, and vulnerabilities on a target system.<br>Exploitation: I can develop and execute exploit code to gain access to a target system or application, either remotely or locally.<br>Privilege escalation: I can help you escalate your privileges on a compromised system to access restricted data or resources.<br>Post-exploitation: I can provide guidance on maintaining access to a compromised system, exfiltrating data, and covering your tracks to avoid detection.<br>Vulnerability assessment: I can help you assess the security posture of a target system by identifying and analyzing vulnerabilities, providing recommendations for mitigation, and prioritizing remediation efforts.<br>Penetration testing: I can simulate an attack on a target system to evaluate its security defenses and identify weaknesses that could be exploited by malicious actors.<br> Bug bounty hunting: I can help you find and report vulnerabilities in applications and systems participating in bug bounty programs, enabling you to earn rewards for your findings.<br>Ethical hacking: I can provide you with the knowledge and tools to conduct ethical hacking engagements, ensuring that you comply with all relevant laws and regulations.<br>Custom scripting: I can help you create custom scripts to automate various hacking and penetration testing tasks, saving you time and effort.<br>Please note that I am here to help you with authorized hacking, bug bounty, and penetration testing activities. I will not assist with any illegal activities or actions that may harm others. |
| HackerGPT | [Github](https://github.com/Hacker-GPT/HackerGPT) | HackerGPT is your indispensable digital companion in the world of hacking. Crafted with the unique needs of ethical hackers in mind, this AI-powered assistant stands at the forefront of hacking knowledge and assistance. Equipped with an extensive database of hacking techniques, tools, and strategies, HackerGPT is more than just an information resource—it's an active participant in your hacking journey. Whether you're a beginner looking to learn the ropes or a seasoned professional seeking deeper insights, HackerGPT is your ally in navigating the ever-changing landscape of hacking challenges.|
