#Dark LLMs aka BlackHat GPTs and Malicious AIs

While most LLMs/AIs have ethical guardrails that would require a [jailbreak](https://zvelo.com/how-ai-jailbreaks-pave-the-way-for-unskilled-attackers/) to bypass those built-in limitations, there are some AIs and LLMs that are not designed with those limitations.
These Dark LLMs and Malicious AIs are intended to be weaponized for cyberattacks.

[Zvelo](https://zvelo.com/malicious-ai-the-rise-of-dark-llms/) had a article on the topic recently, noting, "Dark LLMs are AI-powered tools that leverage OpenAI’s API to engineer malicious variations of ChatGPT that operate without any sort of ethical guidelines or built-in limitations. Tailor made for the vast cybercriminal networks, the main goal of the dark LLMs is to facilitate nefarious activities. At this point, they have primarily been observed being utilized to generate malicious code, exploit vulnerabilities, and create targeted spear-phishing emails."

##The following is provided for research purposes ONLY.


|Name | Link | Description |
|-----------| ------------- | ------------------------------------------------------ |
|XXXGPT| [Link](https://twitter.com/FalconFeedsio/status/1685915834718269440/photo/1) | XXXGPT is a malicious iteration of ChatGPT, engineered for illicit activities. The tool claims to offer a broad spectrum of functions to facilitate various types of cyberattacks including botnets for large-scale attacks, Remote Access Trojans (RATs), Crypters, and malware creation. Notably, it excels in producing hard-to-detect malware, thanks to its convincing nature and an advanced obfuscation feature. This obfuscation capability significantly enhances its ability to camouflage the code it generates, making the malware challenging to identify and thwart, thereby adding a complex layer to cybersecurity defense strategies. |
|Wolf GPT | [Link](link)| Wolf GPT, a malicious variant of ChatGPT, harnesses Python programming to craft cryptographic malware from extensive datasets of existing malicious software. Distinguished by its ability to enhance attacker anonymity within specific attack vectors, it also facilitates advanced phishing campaigns. Similar to XXXGPT, Wolf GPT possesses an obfuscation feature that considerably hampers cybersecurity teams’ efforts to detect and mitigate these sophisticated threats. |
|WormGPT |[Link](link)| WormGPT, built on the GPT-J language model developed in 2021, is a tool designed for cybercriminal activities, especially focused on malware creation and exploitation. It stands out with features like unlimited character support, chat memory retention, and code formatting capabilities. WormGPT is known for its rapid response times, expansive character count handling, and a strong emphasis on privacy, avoiding the logging or retention of user data. Its versatility is enhanced by various AI models, allowing dynamic usage and prompt alteration. Notably, it includes ongoing development in context memorization and offers formatted code and scripts in responses, tailored to cater to code-related queries. |
|DarkBARD | [Link](link)| DarkBARD AI, the evil twin of Google’s BARD AI, is an advanced tool equipped for a range of cybercrimes. It’s defined by its real-time processing of information from the clear web, enhancing its adaptability. DarkBARD AI’s capabilities extend to creating misinformation, deepfakes, and managing multilingual communications. It can generate diverse content like code and articles and integrates with Google Lens for image-related tasks. This tool’s versatility is further underscored by its potential in executing ransomware and DDoS attacks.|
|FraudGTP| [Link](link)|FraudGPT is described as a great tool for creating undetectable malware, writing malicious code, finding leaks and vulnerabilities, creating phishing pages, and for learning hacking. The author illustrated its product with a video demo showing FraudGPT’s capabilities. The demo shows FraudGPT’s ability to create phishing pages and phishing SMSs. |
|Gemma open models| [Google][https://blog.google/technology/developers/gemma-open-models/] | While not explicitly created for mlaicious purposes, as a open model it relies on users implementing a "responsible AI toolkit" to ensure safety and ethics. |
